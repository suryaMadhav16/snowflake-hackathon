2025-01-30 12:07:39,751 - INFO - Starting crawler application
2025-01-30 12:07:39,752 - INFO - Initializing Snowflake session...
2025-01-30 12:07:39,755 - INFO - Snowflake Connector for Python Version: 3.12.4, Python Version: 3.11.11, Platform: macOS-15.3-arm64-arm-64bit
2025-01-30 12:07:39,757 - INFO - Connecting to GLOBAL Snowflake domain
2025-01-30 12:07:39,757 - INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
2025-01-30 12:07:40,539 - INFO - Snowpark Session information: 
"version" : 1.26.0,
"python.version" : 3.11.11,
"python.connector.version" : 3.12.4,
"python.connector.session.id" : 3043392353602742,
"os.name" : Darwin

2025-01-30 12:07:40,539 - INFO - Successfully connected to Snowflake
2025-01-30 12:07:51,697 - INFO - Starting crawler application
2025-01-30 12:07:53,470 - INFO - Starting crawler application
2025-01-30 12:07:53,474 - INFO - Discovering URLs for https://docs.omnivore.app/using/install.html in single mode
2025-01-30 12:07:53,593 - INFO - Successfully discovered 1 URLs for domain docs.omnivore.app
2025-01-30 12:07:57,510 - INFO - Starting crawler application
2025-01-30 12:07:57,522 - INFO - Starting crawl for 1 URLs
2025-01-30 12:08:09,584 - ERROR - Crawling failed: 500 Server Error: Internal Server Error for url: http://localhost:8000/api/v1/crawl
Traceback (most recent call last):
  File "/Users/saisuryamadhav/Documents/snowflake-hackathon/frontend/pages/1_üï∑Ô∏è_Crawler.py", line 232, in main
    response = api_client.crawl_urls(selected_urls, exclude_patterns)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/saisuryamadhav/Documents/snowflake-hackathon/frontend/services/api_client.py", line 77, in crawl_urls
    return self._make_request("POST", "crawl", data, timeout=600)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/saisuryamadhav/Documents/snowflake-hackathon/frontend/services/api_client.py", line 32, in _make_request
    response.raise_for_status()
  File "/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: http://localhost:8000/api/v1/crawl

2025-01-30 12:18:08,708 - INFO - Starting crawler application
2025-01-30 12:18:16,211 - INFO - Starting crawler application
2025-01-30 12:18:17,933 - INFO - Starting crawler application
2025-01-30 12:18:17,936 - INFO - Discovering URLs for https://docs.omnivore.app/using/inbox.html in single mode
2025-01-30 12:18:18,046 - INFO - Successfully discovered 1 URLs for domain docs.omnivore.app
2025-01-30 12:18:20,045 - INFO - Starting crawler application
2025-01-30 12:18:20,061 - INFO - Starting crawl for 1 URLs
2025-01-30 12:18:30,574 - ERROR - Crawling failed: 500 Server Error: Internal Server Error for url: http://localhost:8000/api/v1/crawl
Traceback (most recent call last):
  File "/Users/saisuryamadhav/Documents/snowflake-hackathon/frontend/pages/1_üï∑Ô∏è_Crawler.py", line 232, in main
    response = api_client.crawl_urls(selected_urls, exclude_patterns)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/saisuryamadhav/Documents/snowflake-hackathon/frontend/services/api_client.py", line 77, in crawl_urls
    return self._make_request("POST", "crawl", data, timeout=600)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/saisuryamadhav/Documents/snowflake-hackathon/frontend/services/api_client.py", line 32, in _make_request
    response.raise_for_status()
  File "/opt/anaconda3/envs/getting_started_llmops/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: http://localhost:8000/api/v1/crawl

